
企业环境中使用 DeepSeek、豆包及 Claude AI 工具的数据泄露风险评估报告
I. 执行摘要
* 概述: 本报告旨在评估在标准家庭或办公网络环境（包括有防火墙的环境）中使用 DeepSeek、豆包（Doubao）和 Claude 这三款人工智能（AI）工具处理包含企业真实数据的材料时，潜在的企业敏感数据泄露风险。综合评估显示，在公共或消费者版本层面，DeepSeek 的风险最高，豆包的风险为中高，Claude 消费者版本的风险为中低。对于设计用于处理敏感数据的企业级解决方案，Claude 企业版的风险最低。
* 关键发现: 各服务提供商在关键风险维度上存在显著差异。数据驻留地方面，DeepSeek 和豆包（通过其母公司字节跳动）与中国关联紧密，其数据存储和处理可能受中国法律管辖 1，而 Claude（Anthropic）主要在美国/欧盟法律框架下运营。默认数据用于训练方面，DeepSeek 和豆包的公开版本政策允许或明确将用户输入用于模型训练 3，而 Claude 消费者版本默认不使用用户数据进行训练，但存在信任与安全审查的例外情况 5。安全态势与合规认证方面，Anthropic (Claude) 拥有包括 SOC 2、ISO 27001 在内的多项权威认证 7，而 DeepSeek 和豆包则缺乏此类公开可验证的认证信息，且 DeepSeek 存在多起已报告的安全漏洞和数据泄露事件 9。
* 核心建议: 强烈不建议使用任何 AI 工具的公共或免费版本处理敏感的企业数据。对于涉及此类数据的任务，应优先选用提供明确数据安全和隐私保护承诺的企业级解决方案（如 Claude 企业版），或在严格的内部控制、用户培训和技术防护措施下谨慎使用。鉴于 DeepSeek 存在显著的安全问题和数据驻留地风险，建议对其使用采取极其审慎的态度，甚至考虑禁止在企业环境中使用。
II. 引言
* 背景: 随着生成式人工智能技术的飞速发展，DeepSeek、豆包和 Claude 等 AI 工具正越来越多地被企业员工用于提高工作效率，例如撰写报告、分析数据、编写代码等 11。这种趋势为企业带来了生产力提升的机遇，但也伴随着新的安全挑战。
* 问题陈述: 核心问题在于，当员工在标准家庭或办公网络环境下，使用这些第三方云 AI 服务处理包含敏感信息的材料时（例如用户提到的“企业真实数据”、“网络安全”、“防火墙”配置详情等），存在企业核心数据意外泄露给服务提供商或其他未授权方的风险。这些风险可能源于服务提供商的数据处理策略、安全漏洞、网络传输过程中的脆弱性，以及用户自身的操作失误或终端安全问题。
* 报告目标与范围: 本报告旨在基于用户提出的具体问题（涵盖服务商政策、数据训练用途、网络风险、企业版本、安全事件与合规、敏感信息输入风险、用户端风险等八个方面）和提供的研究材料，对在所述场景下使用 DeepSeek、豆包和 Claude 导致企业敏感数据泄露的可能性进行详细的风险评估，并提供相应的缓解建议。
III. AI 服务提供商数据处理政策与实践
* A. 数据收集、存储与处理
   * DeepSeek: 根据其隐私政策和相关分析，DeepSeek 收集广泛的用户数据，包括用户提供的个人资料（如生日、邮箱、电话号码）、输入的提示（Prompts）、聊天记录、上传的文件，以及自动收集的技术信息，如设备型号、操作系统、IP 地址、设备标识符、Cookie，甚至包括“击键模式或节奏” 1。其政策明确指出，收集的信息存储在位于中华人民共和国境内的安全服务器上 1。此外，其使用条款规定，任何争议将受中国大陆法律管辖，并在 DeepSeek 注册地（目前为中国杭州）的法院解决 13。
   * 豆包 (Doubao): 作为字节跳动旗下的产品 15，豆包的隐私政策表明会收集实现功能所必需的信息，包括用户主动输入的文本、图片、语音等 4。数据的保留期限与提供服务和用户账号状态相关 4。用户需对提交信息的真实性负责 16。考虑到其与字节跳动的关系以及字节跳动广泛的基础设施（包括火山引擎）17，豆包的数据处理和存储很可能利用字节跳动的全球（含中国）基础设施。
   * Claude (Anthropic): Anthropic 明确区分其消费者产品（如免费版 Claude.ai、Claude Pro）和商业产品（如 API、企业版）19。收集的数据类型包括用户输入与输出、账户信息、技术信息等 21。对于消费者产品，对话数据会保留以提供持续的产品体验（如保存聊天记录），但后端系统会在 30 天内自动删除输入和输出，除非被信任与安全（Trust & Safety, T&S）团队标记以执行使用政策或满足法律要求 19。商业和企业级服务则提供零数据保留选项或允许客户自定义数据保留期 19。鉴于其对 GDPR、SOC 2 等合规性的重视 7，其数据处理中心很可能位于美国或欧盟。
   * 地缘政治风险的放大效应: DeepSeek 和豆包的数据存储与处理与中国的关联 1 引入了超越传统数据安全范畴的地缘政治风险。标准的风险评估通常关注来自网络犯罪分子或竞争对手的未授权访问，然而，当数据驻留在特定司法管辖区（如中国）时，国家行为者也成为潜在的威胁来源。中国的国家安全法和网络安全法可能允许政府机构在特定情况下要求访问企业数据 1，这可能优先于服务商的商业隐私承诺 1。即使服务商主观意愿是保护数据，也可能面临法律强制要求披露数据给政府的压力。对于包含网络安全细节、商业秘密或其他敏感信息的企业数据而言，这构成了高影响性的泄露风险，与主要在美欧法律框架下运营的服务商（如 Anthropic）形成了根本性的风险差异。
   * 击键模式收集的特殊风险: DeepSeek 收集“击键模式或节奏” 12 的做法引发了额外的隐私担忧。尽管声称并非记录具体按键（Keylogging），但这本质上是一种生物特征信息的收集。这种模式可以用于区分不同用户，形成一种生物识别标识 12。将此类数据存储在中国 12，进一步增加了风险。一旦泄露，这些信息可能被用于身份冒充或跨平台追踪用户。更令人不安的是，其隐私政策并未明确说明将如何使用这些信息 12，这种不透明性加剧了相关风险。
* B. 用户数据用于模型训练
   * DeepSeek: 其隐私政策和使用条款明确指出，用户的输入（Inputs）和输出（Outputs）可能会被用于改进服务、开发新技术以及训练机器学习模型和算法 3。隐私政策中提到使用信息“训练和改进我们的技术，例如我们的机器学习模型和算法” 3。
   * 豆包 (Doubao): 其隐私政策提到，为了提供和改进问答、学习、创作等服务，平台可能收集用户输入的信息，并且这些收集到的数据以及模型生成的回应，在经过安全加密、严格去标识化处理并确保无法重新识别到特定个人的前提下，可能被用于模型训练，以持续优化模型性能 4。尽管字节跳动曾公开声明否认使用用户未公开的私人数据进行训练 25，但其政策文本保留了这种可能性。
   * Claude (Anthropic):
      * 消费者版本 (Free/Pro): 默认情况下，不使用用户的输入或输出来训练其生成模型 5。存在两种例外情况：1) 用户通过反馈机制（如点赞/点踩）或直接联系方式明确授权 6；2) 对话被信任与安全（T&S）团队标记进行审查，这种情况下数据可能被用于改进 T&S 检测能力和相关模型（并非用于训练通用生成模型）5。
      * 商业版本 (API/Enterprise): 默认情况下，不使用客户数据进行模型训练 22。唯一的例外是客户明确报告了某些材料（例如通过反馈机制）或以其他方式明确选择加入训练 33。
   * “免费陷阱”现象: DeepSeek 以及潜在的豆包（尽管有公开否认 25，但政策 4 允许）遵循了许多免费或公共 AI 工具的普遍模式：用户数据是改进模型和服务的重要资源 28。免费服务需要价值交换，而用户数据往往是这种交换的一部分 37。DeepSeek 的政策对此直言不讳 3。豆包的政策也留有余地 4。相比之下，Anthropic 对消费者版本采取的默认不训练策略是一个显著的差异化优势，但仍需注意其 T&S 审查例外条款。这凸显了使用免费工具与维护企业数据机密性之间固有的潜在冲突。免费层级对于处理机密数据而言，其固有风险高于那些将数据保护作为核心功能设计的企业级版本 20。
   * 训练数据的“后门”风险: Anthropic 消费者版本的 T&S 例外条款 5 构成了一种微妙的风险。虽然声称不用于训练主要的生成模型，但被标记的数据（如果员工不当使用，可能包含敏感企业信息）会被人工审查，并可能用于训练内部的 T&S 模型 5。这仍然是一种数据暴露和利用形式。用户看到“不用于训练”的承诺时，可能不会预料到这种例外情况。尽管目的不同于提升通用模型性能，但敏感数据仍被访问和使用，创造了一种用户可能未充分意识到的暴露风险。
* C. 数据共享政策（第三方、政府）
   * DeepSeek: 其隐私政策表明，可能与广告和分析合作伙伴共享通过使用服务收集的个人数据 1。数据也可能与其公司集团内部实体共享 1，以及向提供服务的第三方供应商共享（例如，为提供搜索服务而集成 Bing API）3。在公司合并、出售、重组等交易中，用户信息也可能被披露 1。此外，DeepSeek 可能根据法律要求或为保护用户、版权所有者及他人的权利、财产和安全，或调查违规行为、处理非法活动等目的，与执法机构、公共当局或其他第三方共享用户信息。政策声称此举将符合“国际公认标准”，但最终受制于数据存储地（中国）的法律 3。
   * 豆包 (Doubao): 其数据共享政策可能遵循字节跳动的标准。字节跳动的通用安全页面提到保护用户隐私 17。其云服务（火山引擎）使用了多家公有云 38，暗示可能存在与其他方的数据交互。考虑到其中国背景，其政策很可能允许在法律合规要求下共享数据，与 DeepSeek 类似。
   * Claude (Anthropic): 与 DeepSeek 类似，Anthropic 也可能与服务提供商、公司集团共享数据，在公司交易中披露信息，经用户同意后共享，或出于法律、安全原因共享 21。关键区别在于其运营受美国/欧盟法律框架约束。政府信息请求会根据其特定政策处理 39，通常需遵循美国的法律程序。企业级服务的协议中可能有更严格的数据共享限制 22。
   * 法律框架的重要性: 尽管所有提供商都列出了相似的数据共享场景（如服务提供商、法律合规），但管辖法律框架和数据驻留地极大地改变了这些条款的实际含义，尤其是在政府访问方面。DeepSeek 和豆包的中国背景 2 意味着政府的数据访问请求可能面临较低的透明度和更宽泛的范围，这与适用于 Anthropic 的美欧法律体系下的情况不同 3。政策中允许为履行“法律义务”而共享数据的条款 3 听起来很标准，但“法律义务”的定义在中美欧之间存在显著差异。中国的国家安全法可能授权广泛的数据访问权限 1。而在美欧，法律程序通常涉及搜查令、传票和司法监督，为数据提供更多潜在的保护和透明度 39。因此，对于存储在中国司法管辖区内的数据，政府访问的实际风险更高且更难预测。
* D. 用户权利与控制（数据删除、选择退出机制）
   * DeepSeek: 用户可以通过设置删除聊天记录 2。可以删除账户，但部分数据可能依法保留 3。其政策中未明确提供通用的、选择不将数据用于模型训练的选项 3，但用户可以通过邮件反馈意见 3。用户根据适用法律（即中国法律）享有访问、更正、删除等权利 3。
   * 豆包 (Doubao): 用户可以删除发布的信息或注销账户 4。政策明确提供了选择退出（Opt-out）数据用于模型训练的途径：用户可以通过隐私政策中提供的联系方式联系平台提出请求 4。关于数据访问、删除等通用权利，可能遵循字节跳动的整体政策 17。
   * Claude (Anthropic): 用户可以删除对话（立即从历史记录中移除，30 天内从后端删除）19。可以删除账户。消费者用户默认选择退出（Opt-out）数据用于模型训练 5。企业用户通过服务协议拥有更强的控制权，包括自定义数据保留期甚至零保留 19。用户根据 GDPR、CCPA 等适用法规享有相应的数据主体权利 26。
   * 选择退出机制的清晰度差异: 各服务在提供“选择退出数据用于训练”选项方面的便捷性和清晰度存在显著差异。Anthropic 为消费者提供了清晰的“默认退出”设置 5，这是最有利于隐私保护的方式。豆包则要求用户主动联系平台以选择退出 4，将操作负担放在了用户身上。DeepSeek 的政策则缺乏明确的通用退出机制 3，暗示默认接受训练是使用服务的条件。这种差异直接影响了用户在不知情或不采取行动情况下的被动风险暴露程度。对于企业而言，这进一步强调了依赖明确的合同条款（如企业版协议）而非消费者默认设置的重要性。
* E. 表 1: 消费者版本数据训练政策与选择退出机制比较
   * 位置: 第三节末尾。
   * 内容:


功能特性
	DeepSeek (公开版)
	豆包 (公开版)
	Claude (免费版/Pro 消费者版)
	默认用于训练?
	是 3
	是，政策允许 4 (尽管公关否认 25)
	否 5
	提供明确的选择退出?
	政策中无明确通用选项 3
	是，通过联系平台 4
	不适用 (默认即退出)
	选择退出方式
	通过邮件反馈 3
	通过隐私政策第9节联系方式 4
	不适用
	不用于训练的例外
	不适用 (默认训练)
	不适用 (默认允许训练)
	1. 用户明确许可 (反馈/请求) 6。 2. 信任与安全审查 5。
	关键参考片段
	1
	4
	5
	





*   **价值说明:** 该表直观地比较了员工最可能接触到的消费者版本在处理用户数据用于训练方面的政策——这是企业数据泄露的一个核心关切点。它直接回应了用户查询的第 2 点，并清晰地展示了 Anthropic 相较于 DeepSeek 和豆包在默认设置上更为保护隐私的立场，同时也指出了 Claude 存在的 T&S 例外情况。这有助于快速区分各服务在此特定风险向量上的差异。

IV. 安全态势、合规性与事件历史
* A. 安全措施与合规认证 (ISO 27001, SOC 2)
   * DeepSeek: 其隐私政策声称采取了“商业上合理”的技术、管理和物理安全措施 3。但在审查的官方政策和研究片段中，并未提及获得 SOC 2 或 ISO 27001 等行业标准认证 40。虽然其合作伙伴 GPTBots 声称其基于 DeepSeek 的本地化部署方案符合相关合规标准 45，但这并不代表 DeepSeek 服务本身或其云平台通过了认证。相反，多项外部安全分析报告指出了 DeepSeek 存在的安全缺陷 2。
   * 豆包 (Doubao): 其隐私政策笼统地提到了采取合理的安全措施，如加密、访问控制、安全审计和应急响应计划 4。同样，没有信息表明豆包服务本身已获得 SOC 2 或 ISO 27001 认证 47。其安全性很可能依赖于母公司字节跳动及其火山引擎云平台的基础设施和安全实践 17。
   * Claude (Anthropic): Anthropic 在安全合规方面表现突出，已获得 SOC 2 Type II 认证 7 和 ISO 27001:2022 认证 7。此外，还获得了 ISO 42001（人工智能管理体系）认证 7，并提供符合 HIPAA（美国健康保险流通与责任法案）要求的选项 24。Anthropic 利用安全的云基础设施（如 AWS 和 GCP）21，并设有公开的信任中心/门户网站以展示其安全承诺和合规状况 7。
   * 合规认证的价值差异: Anthropic 拥有的、可公开验证的合规认证组合（SOC 2, ISO 27001/42001, HIPAA 选项）为企业用户提供了一个重要的信任基线，并简化了尽职调查过程 7。相比之下，基于现有信息，DeepSeek 和豆包似乎缺乏此类行业标准认证。这意味着企业在评估这两个服务时，不得不更多地依赖于对其政策的解读、服务商的自我声明 3 或第三方的（通常对 DeepSeek 是负面的 2）报告，这无疑增加了评估的难度和感知风险。诸如 ISO 27001 和 SOC 2 57 的认证是对服务商安全实践的独立验证。Anthropic 提供了这种验证 7，而 DeepSeek/豆包（根据现有资料）则没有。缺乏外部验证，再加上 DeepSeek 的负面安全报告 9，使得信任它们处理敏感数据的风险远高于信任已经过严格审计的 Anthropic。
* B. 安全漏洞与数据泄露历史
   * DeepSeek: 第三方报告揭示了其较多的安全问题。该平台易受“越狱”（jailbreaking）和提示注入（prompt injection）攻击，可被诱导生成恶意软件或提供进行非法活动的指导 2。2025 年 1 月，Wiz Research 发现一个属于 DeepSeek 的 ClickHouse 数据库可被公开访问且无需身份验证，泄露了包括聊天记录、API 密钥、后端细节和操作日志在内的大量敏感信息 2。对其 Android 应用程序的分析发现了弱加密算法、SQL 注入风险、硬编码密钥以及反调试机制等问题 46。还有报告声称发现其存在将用户信息直接发送到中国政府服务器的后门 9，以及包含过时的加密技术和易受 SQL 注入攻击的漏洞 9。DeepSeek 自身也曾因“恶意攻击”而限制新用户注册 2。意大利、澳大利亚以及美国海军等机构曾因安全或隐私担忧而对其发出禁令或警告 2。
   * 豆包 (Doubao): 公开报告的安全事件相对 DeepSeek 较少。2024 年 12 月曾发生一起事件，用户通过豆包搜索到了他人的（已在网上公开过的）微信联系方式及其他个人信息 61。豆包平台回应称其行为类似于搜索引擎，抓取和整合了互联网上的公开信息 61。此外，存在对 AI 数据泄露的普遍担忧 62。其安全性依赖于字节跳动的基础设施 17。
   * Claude (Anthropic): 其状态页面记录了一些服务性能下降或错误率升高的问题 63。最引人注目的是 2024 年 1 月发生的一次数据泄露事件，起因是其承包商的人为失误：一封未受保护的电子邮件被发送给第三方，其中包含部分客户的姓名和未结信用余额（不含银行或支付信息）64。Anthropic 在发现后迅速启动调查并向受影响客户发出通知，强调这是孤立的人为错误，并非系统性漏洞 64。此外，在一个有组织的红队演练中，参与者成功绕过了 Claude 3.5 的安全措施 66，这反映了 AI 安全防护领域持续面临的挑战。
   * 事件处理的透明度与成熟度: 安全事件的性质和披露方式可以反映服务商的安全成熟度。DeepSeek 的问题似乎更具系统性，且大多由外部研究人员发现并报告 2，这可能暗示其内部安全实践或透明度存在不足。Anthropic 的主要事件是人为失误，且由公司主动披露 64，虽然事件本身不理想，但这通常表明其拥有较好的内部监控和更透明的沟通文化。豆包的事件 61 则揭示了 AI 可能以意想不到的方式聚合和呈现公开信息，属于另一类风险。一个被外部发现存在系统性漏洞的服务商（DeepSeek 9）所带来的持续风险，通常高于一个主动披露并已控制住的人为错误事件的服务商（Anthropic 64）。在外部发现之前缺乏披露（DeepSeek 的情况）会侵蚀信任，而主动、妥善地处理和披露（Anthropic 的情况）反而可能在一定程度上重建信任。这种历史表现是评估未来风险的关键指标。
* C. 地缘政治考量与数据主权
   * DeepSeek/豆包: 两者均与中国有紧密联系（DeepSeek 总部在中国 1，豆包隶属字节跳动 15）。DeepSeek 确认数据存储在中国 1，豆包通过字节跳动的基础设施也很可能涉及中国。这意味着它们的数据处理活动受中国法律管辖，引发了关于潜在政府访问、监控甚至产业间谍活动的担忧 1。DeepSeek 的使用条款明确规定适用中国法律 13，并将遵守出口管制法律的责任推给了用户 13。有用户报告观察到其存在内容审查现象 2。这些因素为非中国企业带来了显著的数据主权风险。
   * Claude (Anthropic): Anthropic 是一家美国公司。其服务可能运行在美国或欧盟的数据中心（从其遵守的法规如 GDPR、SOC 2 7 以及使用的云平台如 AWS/GCP 21 可以推断）。这意味着其运营主要受美欧法律框架约束，相对于中国法律，这些框架通常为企业数据提供了更强的、对抗外国政府访问的保护。其合规实践也更清晰地对齐 GDPR、CCPA 等国际主流数据保护法规 7。
   * 地缘政治风险的再强调: 此处深入探讨第三节 A 部分提出的地缘政治风险，重点关注数据主权和地缘政治影响。这种风险并非纯理论性的；研究材料中明确提到了对产业间谍 1 和强制数据上交 1 的担忧，特别是针对像 DeepSeek 这样的中国公司。数据主权意味着数据受其存储地法律的约束。对于 DeepSeek 和豆包，这很可能是中国 1。中国的法律体系优先考虑国家安全和国家利益，这可能包括要求访问私营公司持有的数据 1。对于使用这些工具的外国企业而言，其敏感数据（可能包括商业秘密、网络架构图等）可能被中国政府合法访问，从而构成直接的竞争和安全风险 1。相比之下，当使用像 Anthropic 这样在不同法律框架下运营的服务商时，这种风险在很大程度上不存在或得到了缓解。
V. 企业级解决方案分析
* A. 可用性与功能特性
   * DeepSeek: 其合作伙伴 GPTBots 提供了一种使用 DeepSeek 模型的“本地化部署”（On-Premise）解决方案，声称具备企业级的性能、安全性、可扩展性、基于角色的访问控制（RBAC）和合规性特性 45。然而，鉴于 DeepSeek 公开版本存在的安全问题，外部评估对其是否适合企业使用表示怀疑 2。从现有资料看，DeepSeek 本身是否直接提供企业级云服务尚不明确。
   * 豆包 (Doubao): 没有明确的“豆包企业版”计划被详细介绍。它很可能被整合到字节跳动的火山引擎 MaaS（模型即服务）平台“火山方舟”中 49。火山方舟提供模型精调、评测、推理等服务，集成了多家（可能包括豆包）的模型 67。该平台强调通过安全沙箱保障数据安全 49，并利用字节跳动的大规模基础设施 18。
   * Claude (Anthropic): Anthropic 提供名为“Claude for Work”的企业解决方案，包括 Team（团队）和 Enterprise（企业）两种计划 20。这些计划提供了更高的使用配额、更大的上下文窗口（最高达 500k tokens）23、团队协作功能、单点登录（SSO）、跨域身份管理系统（SCIM）、审计日志、RBAC、自定义数据保留策略、专属支持和 API 访问权限 22。还提供与 GitHub 等外部系统的集成 22。
* B. 增强的安全与数据隐私承诺
   * DeepSeek (通过合作伙伴): GPTBots 声称其本地化部署方案可实现完全的数据主权（数据不出企业）、严格的 RBAC、端到端加密，并符合 GDPR、中国网络安全法等合规要求 45。但需要强调的是，这些是合作伙伴对其特定部署方案的承诺，并非 DeepSeek 服务本身固有的保证。 DeepSeek 自身关于模型使用的条款仍然适用 14。
   * 豆包 (通过火山引擎): 火山方舟平台着重宣传其安全沙箱技术，通过计算隔离、存储隔离、网络隔离和流量审计等方式，在模型使用者、提供者和云平台之间建立信任，以解决数据泄露担忧 49。其安全性依托于字节跳动的整体安全体系 17。
   * Claude (Enterprise): Anthropic 对其企业级服务做出了明确承诺：默认情况下，不使用 Claude for Work 的数据进行模型训练 22。提供企业级的安全特性，如 SSO、SCIM、审计日志、RBAC 22。允许客户自定义数据保留控制 22。拥有 SOC 2、ISO 27001、ISO 42001 等认证以及 HIPAA 合规选项，提供了可验证的安全保障 7。还为付费商业服务提供版权赔偿保护 50。
* C. 处理敏感企业数据的适用性
   * DeepSeek: 基于其公开版本暴露的安全问题 2 和数据驻留中国的风险 1，其适用性非常值得怀疑。即使是合作伙伴提供的本地化部署方案 45，也使用了 DeepSeek 的底层模型，可能继承了固有风险，需要极其谨慎的评估。在没有大量独立的验证和缓解措施的情况下，使用 DeepSeek 处理敏感数据似乎风险过高。
   * 豆包 (通过火山引擎): 如果火山方舟的安全沙箱 49 能够有效隔离数据、防止滥用和泄露，并且合同条款能保证不将数据用于训练并解决数据驻留地的顾虑，那么它可能适用于某些场景。然而，它仍然受到字节跳动/中国监管环境的影响。需要对火山引擎的具体保证和技术实现进行彻底的尽职调查。
   * Claude (Enterprise): Claude 企业版是明确为企业使用场景设计的，具备强大的安全功能、合规认证和清晰的数据处理政策（默认不训练）7。基于所提供的证据，在三者之中，Claude 企业版似乎最适合处理敏感的企业数据，提供了最高水平的保障。
   * 企业版本的必要性: 消费者版本和企业版本在安全承诺与功能上的巨大差距（尤其对 Claude 而言 6）清楚地表明，使用消费者版本处理敏感企业数据是不恰当的。企业级服务正是为了解决这些风险而设计（并定价）的。服务商提供企业级选项 22，本身就意味着他们认识到消费者版本缺乏企业所需的必要安全、隐私和合规控制。像默认不训练 22、SSO 22、审计日志 22、自定义保留期 22 和认证 7 等功能通常是付费/企业计划独有的。选择免费或消费者版本，实际上是主动选择了一个风险更高的选项。
* D. 表 2: 关键企业级安全/隐私特性比较
   * 位置: 第五节末尾。
   * 内容:


功能特性
	DeepSeek (通过合作伙伴本地部署 )
	豆包 (通过火山引擎 MaaS )
	Claude (企业版 )
	可用性
	通过合作伙伴 (GPTBots)
	通过火山引擎平台
	直接来自 Anthropic
	数据训练 (默认)
	合作伙伴声称隔离；底层模型政策?
	平台旨在隔离 49；需合同约定
	否 22
	数据驻留选项
	本地部署 (通过合作伙伴) 45
	很可能字节跳动基础设施 (可能含中国)
	很可能美国/欧盟 (基于合规性)
	关键安全特性
	RBAC, 端到端加密 (合作伙伴声称 45)
	安全沙箱 (隔离, 审计) 49
	SSO, SCIM, 审计日志, RBAC 22
	合规认证
	合作伙伴声称对齐 45；DeepSeek 不明确
	依赖字节跳动/火山引擎态势
	SOC 2, ISO 27001, ISO 42001, HIPAA 选项 7
	自定义保留期
	本地部署可能可配置
	需合同约定
	是 22
	关键参考片段
	2
	17
	7
	





*   **价值说明:** 该表直接回应了用户查询的第 4 点，比较了面向企业的解决方案。它突出了各方案在安全特性、数据处理承诺和合规验证方面的显著差异，使用户能够就哪种（或哪些）企业解决方案可能满足其处理敏感数据的要求做出更明智的判断。它显示 Claude 企业版基于现有信息拥有最强大和可验证的产品。同时，它也指出了 DeepSeek 本地化选项依赖于合作伙伴的声明，而豆包/火山引擎则需要具体的合同细节，为进一步的尽职调查提供了方向。

VI. 敏感数据泄露的综合风险评估
* A. 服务提供商侧风险（政策差距、安全弱点、数据滥用）
   * DeepSeek: 高风险。理由：强制数据存储在中国 1，政策明确允许用于训练且无清晰退出选项 3，有严重的安全漏洞和数据泄露历史记录 2，缺乏行业标准认证，存在潜在的政府访问风险 1。
   * 豆包: 中高风险。理由：与中国的关联及字节跳动的所有权意味着类似的驻留地/访问风险，政策允许训练（但提供退出选项）4，公开的安全事件较少但仍存在数据意外暴露的担忧 61，安全性依赖于需要验证的字节跳动整体态势。
   * Claude: 中低风险（消费者版），低风险（企业版）。理由：消费者版默认不训练是优势 5，但 T&S 审查是潜在漏洞 5；过去的人为失误泄露事件已处理 64。企业版提供强大的合同保证（不训练、自定义保留）22，健全的安全功能 22，以及强大的合规认证基础 7。
* B. 网络传输风险（标准办公/家庭环境）
   * 普遍风险: 通过互联网传输数据，即使使用 TLS/SSL 加密（HTTPS 的标准），也始终存在固有风险。这些风险包括在受损网络（如恶意公共 Wi-Fi、被入侵的家庭路由器）上被截获、中间人攻击（在正确验证 TLS 的情况下可能性较低），或 TLS 协议本身的漏洞（罕见）。
   * 防火墙的作用: 标准的家庭或办公室防火墙主要控制入站流量，并进行基本的出站端口/协议过滤。它们通常不检查加密的 HTTPS 流量内容，因此对于在合法连接内流向云 AI 服务的数据泄露提供的保护作用微乎其微。更高级的企业级防火墙（如具备 SSL 解密功能的 NGFW 或代理服务器）可能监控或阻止敏感数据传输，但这会增加复杂性、性能开销，并可能引发新的隐私问题。
   * 风险水平: 假设使用标准的 HTTPS 加密，传输本身的风险通常为低至中等，但在网络卫生状况较差（如使用不受信任的网络）时风险会升高。防火墙对此特定场景的缓解作用有限。
* C. 用户终端风险（恶意软件、网络钓鱼、配置不当、内部威胁）
   * 恶意软件: 受感染的终端设备（笔记本电脑、台式机）可以在数据发送给 AI 之前就捕获数据。键盘记录器（属于间谍软件或木马的一部分 71）可以直接窃取输入内容。勒索软件可能加密本地副本 71。
   * 网络钓鱼/社会工程: 诱骗用户泄露其 AI 账户或公司系统的凭证 71。攻击者可能借此访问历史对话或滥用账户。利用 AI 生成的钓鱼邮件正变得越来越逼真 72。
   * 配置不当: 设备上使用弱密码、安全设置配置错误 73、系统未及时打补丁 71 等都会为攻击者创造入口。
   * 内部威胁: 恶意内部人员故意将敏感数据复制粘贴到 AI 工具中 71。疏忽的内部人员可能意外粘贴敏感数据，或使用个人/免费 AI 账户处理工作任务 72。
   * 风险水平: 中高风险。因为终端设备的安全性通常不如企业服务器那样受到严格控制，尤其是在家庭办公环境中。无论 AI 服务提供商自身的安全性如何，这都是一个重要的风险来源。
   * 终端作为最薄弱环节: 不论 AI 服务提供商多么安全（例如 Claude 企业版），一个被攻破的用户终端都可能导致数据在到达安全服务之前就发生泄露 71。如果恶意软件捕获了用户的键盘输入 71 或屏幕内容，或者用户被钓鱼攻击 73，数据在本地就已经失陷。即使传输到 AI 服务的过程是加密的（HTTPS），也无济于事，因为数据在加密前已被窃取。因此，仅仅关注 AI 提供商的安全性（如第三至五节所述）是远远不够的；必须同时解决来自用户终端的风险（第六节 C 部分）。这凸显了将终端安全和用户意识培训作为基础性控制措施的关键重要性。
* D. 输入特定敏感信息（“企业真实数据”、“网络安全”、“防火墙”）的风险
   * 高度敏感性: 这类信息极其敏感。“企业真实数据”可能包含个人身份信息（PII）、财务数据、知识产权、战略计划等。“网络安全”和“防火墙”的详细信息则相当于打开企业防御大门的钥匙。
   * 训练数据风险: 如果这些信息被用于模型训练（DeepSeek 默认 3，豆包可能 4，Claude 的 T&S 例外 5），敏感内容可能被模型“学习”并在对其他用户的回应中无意泄露，或以意想不到的方式影响模型的行为。
   * 泄露影响: 如果因服务提供商的安全事件（如 DeepSeek 的数据库泄露 10）而泄露，后果将非常严重，可能导致针对性的网络攻击、防御体系被攻破或核心商业秘密曝光 37。
   * 提供商/政府访问风险: 对于可能收到政府访问请求的服务商（尤其是中国的 DeepSeek/豆包 1），提供网络/防火墙细节可能将关键基础设施信息暴露给国家行为者。
   * 知识产权损失: 将商业秘密或专有算法（可能是“企业真实数据”的一部分）输入到一个可能将其用于训练的 AI 中，可能导致这些信息失去商业秘密的法律保护 37。
   * 风险水平: 将此类特定数据输入到公共/免费版本（尤其是 DeepSeek/豆包）的风险极高。即使在配置得当的企业级版本中，如果发生安全事件，也仍然存在风险。
* E. 定性风险评估（公共/消费者版本）
   * DeepSeek: 高风险。理由：强制数据存储在中国 1，明确用于训练且无清晰退出选项 3，安全记录不佳（严重漏洞和泄露事件）2，缺乏认证，存在潜在政府访问风险 1。
   * 豆包: 中高风险。理由：与中国的关联及字节跳动所有权意味着类似的驻留地/访问风险，政策允许训练（但提供退出选项）4，公开的安全事件较少但仍有数据暴露担忧 61，安全性依赖于字节跳动整体态势。
   * Claude (Free/Pro): 中低风险。理由：默认不训练是积极因素 5，拥有较强的合规基础 7，数据很可能驻留在美欧。风险因 T&S 审查的数据使用例外 5 和过去的人为失误泄露 64 而略有提升。与企业版相比，仍不适合处理高度敏感数据。
VII. 缓解策略与建议
* A. 政策、治理与培训
   * 制定清晰的 AI 使用政策: 明确规定 AI 工具的可接受和不可接受的使用场景。严禁将敏感的企业数据（需明确定义类别：如 PII、财务数据、知识产权、网络配置、凭证等）输入到公共/免费 AI 服务中 34。强制要求使用经过批准的企业版 AI 工具处理业务相关事务。
   * 建立 AI 治理机制: 成立一个跨职能团队（包括 IT、安全、法务、合规部门），负责审查和批准 AI 工具及应用场景 74。将 AI 相关风险纳入整体风险管理框架。
   * 强制性用户培训: 对员工进行关于 AI 工具数据泄露风险的教育 37，强调遵守公司政策的重要性，帮助员工识别敏感数据，提高网络钓鱼防范意识 73，并推广安全使用实践。明确违规后果。
* B. 技术控制
   * 终端安全强化: 部署强大的终端保护解决方案（如杀毒软件/EDR），确保操作系统和应用程序及时打补丁，实施安全配置加固，并强制使用多因素认证（MFA）71。考虑使用终端数据防泄漏（DLP）工具，以检测或阻止将敏感数据粘贴到未授权的应用程序或网站。
   * 网络安全措施: 维持严格的防火墙规则，但要认识到其对加密流量的局限性。考虑部署企业级网页代理或云访问安全代理（CASB），启用 SSL 解密和 DLP 功能，以监控或阻止向未经批准的 AI 服务上传敏感数据（需谨慎实施，考虑性能和隐私影响）。确保使用安全的 Wi-Fi 网络（如 WPA2/3-Enterprise），并告诫员工不要使用不受信任的网络。
   * 优先使用企业级 AI 版本: 优先选择并部署企业级 AI 解决方案（如 Claude for Work 22），这些方案通常提供合同保证（如不将数据用于训练）、强大的安全功能（如 SSO、审计日志）和合规认证 7。根据需要配置零数据保留或自定义保留策略 19。
   * 阻止未授权 AI 工具访问: 利用网络层控制（防火墙、代理服务器、DNS 过滤）或终端管理工具，阻止从公司网络或设备访问未经批准的公共 AI 服务（如 DeepSeek 的免费版）。
* C. 安全使用实践
   * 数据最小化原则: 仅向 AI 工具输入完成任务所绝对必需的最少量数据。
   * 匿名化/假名化处理: 在输入数据前，尽可能移除或替换敏感的标识符 34。
   * 审慎对待输出: 对 AI 生成的输出保持警惕，务必核实其准确性，尤其是在用于重要决策时 14。意识到如果模型曾使用敏感输入进行训练，其输出可能无意中包含相关信息的残留。
   * 账户分离: 禁止使用个人 AI 账户处理涉及敏感信息的公司事务。
* D. 供应商风险管理
   * 尽职调查: 在批准任何 AI 工具之前，进行彻底的安全和隐私审查。仔细检查服务商的政策、认证（SOC 2, ISO 27001）、安全事件历史、数据驻留地和法律管辖权 7。
   * 合同协议: 确保与企业级 AI 服务商签订的合同中包含明确条款，涵盖数据所有权、保密性、处理限制（如禁止用于训练）、安全要求、数据保留与删除、违约通知和责任划分等 22。
   * 持续监控: 定期审查供应商的合规性和安全状况。关注新的漏洞报告或政策变更。
VIII. 结论
* 研究结果总结: 本报告的分析揭示了 DeepSeek、豆包和 Claude 在处理企业敏感数据时呈现出显著不同的风险状况。DeepSeek 因其安全记录不佳、数据驻留中国以及不明确的数据使用政策而构成高风险。豆包因其与中国的联系和政策上的模糊性构成中高风险。Claude 的消费者版本虽然默认不训练数据，但存在 T&S 例外，风险为中低。而 Claude 企业版凭借其强大的安全承诺、合规认证和明确的数据保护措施，是处理敏感数据的低风险选择。
* 最终风险展望: 使用任何 AI 工具的公共或免费版本处理敏感的企业数据都存在重大的泄露风险，特别是对于 DeepSeek 和豆包。传统的网络防火墙对此类风险的防护能力有限。用户终端的安全状况和员工的操作行为是极其关键的风险因素。
* 强调主动管理: 报告强调，仅仅依赖 AI 服务提供商的声明是不足够的。企业必须采取多层次、主动的管理方法来缓解数据泄露风险。这包括制定明确的政策、加强用户培训、实施有效的技术控制（特别是强化终端安全和推广使用企业级 AI 服务），以及进行严格的供应商风险管理。在生成式 AI 时代，保持持续的警惕并适应不断变化的技术和风险格局至关重要。
引用的著作
1. A deep(er) dive into DeepSeek's privacy policies - Digiday, 访问时间为 四月 9, 2025， https://digiday.com/media/a-deeper-dive-into-deepseeks-privacy-policies/
2. DeepSeek Security, Privacy, and Governance: Hidden Risks in ..., 访问时间为 四月 9, 2025， https://theori.io/blog/deepseek-security-privacy-and-governance-hidden-risks-in-open-source-ai
3. DeepSeek Privacy Policy, 访问时间为 四月 9, 2025， https://cdn.deepseek.com/policies/en-US/deepseek-privacy-policy.html
4. 隐私协议, 访问时间为 四月 9, 2025， https://lf9-cdn-tos.draftstatic.com/obj/ies-hotsoon-draft/turing/7a518dd9-d4bf-45dd-8fbd-8544dcf381cb.html
5. Is my data used for model training? - Anthropic Privacy Center, 访问时间为 四月 9, 2025， https://privacy.anthropic.com/en/articles/10023580-is-my-data-used-for-model-training
6. I would like to input sensitive data into Free Claude.ai or Claude Pro. Who can view my conversations? - Anthropic Support, 访问时间为 四月 9, 2025， https://support.anthropic.com/en/articles/8325621-i-would-like-to-input-sensitive-data-into-free-claude-ai-or-claude-pro-who-can-view-my-conversations
7. Trust Center - Anthropic, 访问时间为 四月 9, 2025， https://trust.anthropic.com/faq
8. Trust Center - Anthropic, 访问时间为 四月 9, 2025， https://trust.anthropic.com/
9. DeepSeek is unsafe for enterprise use, tests reveal - SD Times, 访问时间为 四月 9, 2025， https://sdtimes.com/ai/deepseek-is-unsafe-for-enterprise-use-tests-reveal/
10. Wiz Research Uncovers Exposed DeepSeek Database Leaking Sensitive Information, Including Chat History, 访问时间为 四月 9, 2025， https://www.wiz.io/blog/wiz-research-uncovers-exposed-deepseek-database-leak
11. 给基层干部学AI点个赞 - 新华网, 访问时间为 四月 9, 2025， http://www.news.cn/comments/20250224/56c68e17a6ca443c85e7d0138aae9980/c.html
12. What DeepSeek's privacy policy means for your personal data | Mashable, 访问时间为 四月 9, 2025， https://mashable.com/article/deepseeks-privacy-policy-your-personal-data
13. DeepSeek Data Security: Safeguarding Your Confidential Information - Tangibly, 访问时间为 四月 9, 2025， https://www.tangibly.com/deepseek-data-security/
14. DeepSeek Terms of Use, 访问时间为 四月 9, 2025， https://cdn.deepseek.com/policies/en-US/deepseek-terms-of-use.html
15. Apifox - API 文档、调试、Mock、测试一体化协作平台。拥有接口文档管理、接口调试、Mock、自动化测试等功能，接口开发、测试、联调效率，提升10 倍。最好用的接口文档管理工具，接口自动化测试工具。, 访问时间为 四月 9, 2025， https://apifox.com/
16. 用户协议 - Trae, 访问时间为 四月 9, 2025， https://www.trae.com.cn/terms-of-service
17. 字节跳动安全中心, 访问时间为 四月 9, 2025， https://security.bytedance.com/
18. 字节火山引擎称不做大模型，H800芯片将是云厂商标品 - 第一财经, 访问时间为 四月 9, 2025， https://m.yicai.com/news/101734279.html
19. How long do you store personal data? | Anthropic Privacy Center, 访问时间为 四月 9, 2025， https://privacy.anthropic.com/en/articles/10023548-how-long-do-you-store-personal-data
20. Claude Policy - Simply Explained - SRX, 访问时间为 四月 9, 2025， https://srx.id/policy/claude
21. Securing the Future of AI: A Deep Compliance Review of Anthropic, Google DeepMind, and OpenAI Under SOC 2, ISO 27001, and NIST, 访问时间为 四月 9, 2025， https://www.tdcommons.org/cgi/viewcontent.cgi?article=9147&context=dpubs_series
22. Enterprise \ Anthropic, 访问时间为 四月 9, 2025， https://www.anthropic.com/enterprise
23. What is the Claude Enterprise plan? | Anthropic Help Center, 访问时间为 四月 9, 2025， https://support.anthropic.com/en/articles/9797531-what-is-the-claude-enterprise-plan
24. Our Commitment to Responsible AI - WorkBoard, 访问时间为 四月 9, 2025， https://www.workboard.com/ai-trust/
25. WPS、字节跳动紧急回应！AI训练再惹争议 - 东方财富, 访问时间为 四月 9, 2025， https://wap.eastmoney.com/a/202407223137073615.html
26. How do you use personal data in model training? - Anthropic Privacy Center, 访问时间为 四月 9, 2025， https://privacy.anthropic.com/en/articles/10023555-how-do-you-use-personal-data-in-model-training
27. Data retention and privacy for Claude 3? : r/ClaudeAI - Reddit, 访问时间为 四月 9, 2025， https://www.reddit.com/r/ClaudeAI/comments/1b7wh1i/data_retention_and_privacy_for_claude_3/
28. Privacy and data protection in AI: ChatGPT and Claude | Navas & Cusi Abogados, 访问时间为 四月 9, 2025， https://www.navascusi.com/en/privacy-data-protection-ia-chatgpt-claude/
29. Your privacy guide to AI chatbots - Section School, 访问时间为 四月 9, 2025， https://www.sectionschool.com/blog/your-privacy-guide-to-ai-chatbots
30. I want to opt out of my prompts and results being used for training models, 访问时间为 四月 9, 2025， https://privacy.anthropic.com/en/articles/10023580-i-want-to-opt-out-of-my-prompts-and-results-being-used-for-training-models
31. AI Assistant Privacy: What Claude, ChatGPT, and Gemini Users Should Know - Medium, 访问时间为 四月 9, 2025， https://medium.com/@michael_79773/ai-assistant-privacy-what-claude-chatgpt-and-gemini-users-should-now-7d3f5cae9e5d
32. On training and privacy : r/ClaudeAI - Reddit, 访问时间为 四月 9, 2025， https://www.reddit.com/r/ClaudeAI/comments/1foyiz0/on_training_and_privacy/
33. What personal data will be processed by computer use (beta)? - Anthropic Privacy Center, 访问时间为 四月 9, 2025， https://privacy.anthropic.com/en/articles/10030352-what-personal-data-will-be-processed-by-computer-use-beta
34. Ultimate Guide how ChatGPT, Perplexity and Claude use Your Data | AMST Legal, 访问时间为 四月 9, 2025， https://amstlegal.com/ultimate-guide-how-chatgpt-perplexity-and-claude-use-your-data/
35. Is my data used for model training? - Anthropic Privacy Center, 访问时间为 四月 9, 2025， https://privacy.anthropic.com/en/articles/7996868-is-my-data-used-for-model-training
36. I want to opt out of my prompts and results being used for training models., 访问时间为 四月 9, 2025， https://privacy.anthropic.com/en/articles/7996868-i-want-to-opt-out-of-my-prompts-and-results-being-used-for-training-models
37. Protecting Sensitive Data in the Age of Generative AI: Risks, Challenges, and Solutions, 访问时间为 四月 9, 2025， https://www.kiteworks.com/cybersecurity-risk-management/sensitive-data-ai-risks-challenges-solutions/
38. 火山引擎宣布与字节国内业务“并池”：复用资源, 访问时间为 四月 9, 2025， http://www.tjyun.com/system/2023/04/18/053836097.shtml
39. Policies & Terms of Service - Anthropic Privacy Center, 访问时间为 四月 9, 2025， https://privacy.anthropic.com/en/collections/10672414-policies-terms-of-service
40. Open-Source AI: DeepSeek's Impact on the Future of SaaS Development, 访问时间为 四月 9, 2025， https://cms.lifeintelligencegroup.com/blog/open-source-ai-deepseek-s-impact-on-the-future-of-saas-development
41. DeepSeek v3: AI's New Game-Changer | Quash Security Certifications, 访问时间为 四月 9, 2025， https://quashbugs.com/newsletter/deepseek-v3-breakthrough-quash-security-certifications
42. Cybersecurity Newsflash: Researchers find security vulnerabilities in DeepSeek for iOS, 访问时间为 四月 9, 2025， https://blog.devolutions.net/2025/02/cybersecurity-newsflash-researchers-find-security-vulnerabilities-in-deepseek-for-ios/
43. Bugbase | ISO 27001 & SOC 2 Certified for Enhanced Security - CertPro, 访问时间为 四月 9, 2025， https://certpro.com/bugbase/
44. DeepSeek's Deep Risks: What You Need to Know - Grip Security, 访问时间为 四月 9, 2025， https://www.grip.security/blog/deepseek-risks-what-you-need-to-know
45. DeepSeek Enterprise On-Premise AI Deployment: Full Guide - GPTBots.ai, 访问时间为 四月 9, 2025， https://www.gptbots.ai/blog/deepseek-enterprise-on-premise
46. A Deep Peek at DeepSeek - SecurityScorecard, 访问时间为 四月 9, 2025， https://securityscorecard.com/blog/a-deep-peek-at-deepseek/
47. SOC 2 vs ISO 27001: What's the Difference and Which Standard Do You Need?, 访问时间为 四月 9, 2025， https://secureframe.com/blog/soc-2-vs-iso-27001
48. ISO 27001 - Compliance Salesforce, 访问时间为 四月 9, 2025， https://compliance.salesforce.com/en/iso-27001
49. 字节的野心：做大模型时代的“军火商” - 华尔街见闻, 访问时间为 四月 9, 2025， https://wallstreetcn.com/articles/3692051
50. Intro to Claude - Anthropic API, 访问时间为 四月 9, 2025， https://docs.anthropic.com/en/docs/intro-to-claude
51. Securing the Future of AI: A Deep Compliance Review of Anthropic, Google DeepMind, and OpenAI Under SOC 2, ISO 27001, and NIST - Technical Disclosure Commons, 访问时间为 四月 9, 2025， https://www.tdcommons.org/dpubs_series/7951/
52. Anthropic - AI Lab Watch, 访问时间为 四月 9, 2025， https://ailabwatch.org/companies/anthropic/
53. Anthropic Claude | Generative AI Tools - Accessibility, Privacy & Security - Amherst College, 访问时间为 四月 9, 2025， https://www.amherst.edu/offices/it/academic-technology-services/tlt/amherst-ai/genai-tools/anthropic-claude
54. AI Product Review for Solo Practitioners and Small Firms: Claude Pro, by Anthropic - State Bar of Nevada, 访问时间为 四月 9, 2025， https://nvbar.org/wp-content/uploads/Claude-AI-Review_Final.pdf
55. Anthropic (Claude) to Customer.io FREE Integrations | Pabbly Connect, 访问时间为 四月 9, 2025， https://www.pabbly.com/connect/integrations/anthropic-claude/customer-io/
56. How Claude + MCP + Vanta could help auditors, 访问时间为 四月 9, 2025， https://www.vanta.com/resources/claude-mcp-vanta
57. ISO 27001 Certification vs SOC 2 Attestation | ISMS.online, 访问时间为 四月 9, 2025， https://www.isms.online/iso-27001/iso-27001-certification-vs-soc-2-attestation/
58. Why ISO 27001 Is Better Than SOC 2 | ISMS.online, 访问时间为 四月 9, 2025， https://www.isms.online/iso-27001/why-iso-27001-is-better-than-soc-2/
59. DeepSeek 'leaking' sensitive data: cybersecurity company says “within minutes, we found…” - The Times of India, 访问时间为 四月 9, 2025， https://timesofindia.indiatimes.com/technology/tech-news/deepseek-leaking-sensitive-data-cybersecurity-company-says-within-minutes-we-found/articleshow/117744155.cms
60. The DeepSeek Cyberattack: A Critical Lesson in Infrastructure Security and the Need for VAPT - [UPDATED: 2025] - CyberSapiens, 访问时间为 四月 9, 2025， https://cybersapiens.com.au/cyber-awareness/learnings-from-the-deepseek-cyberattack/
61. 大厂AI能问出个人微信号？实测各大模型"吞吐"个人信息 - 21财经, 访问时间为 四月 9, 2025， https://www.21jingji.com/article/20241212/herald/0b95d4b52871d223aa1e709c552bb63e.html
62. 实测7款主流大模型，隐私裸奔成通病 - 21财经, 访问时间为 四月 9, 2025， https://m.21jingji.com/article/20250116/herald/02fb2286f4d852407c2e47ad2fd45c07.html
63. Incident History - Anthropic Status, 访问时间为 四月 9, 2025， https://status.anthropic.com/history
64. Anthropic Data Breach | Blog - Bob's Business, 访问时间为 四月 9, 2025， https://www.bobsbusiness.co.uk/resources/ai-startup-anthropic-data-breach-what-you-need-to-know/
65. Data leak at Anthropic - INCYBER NEWS, 访问时间为 四月 9, 2025， https://incyber.org/en/article/data-leak-at-anthropic/
66. Challenges to Anthropic's Security Measures: AI Model Jailbreak Tests Reveal Vulnerabilities - AIbase, 访问时间为 四月 9, 2025， https://www.aibase.com/news/15290
67. 字节旗下火山引擎“挤入”大模型赛道做什么不做什么？ - 第一财经, 访问时间为 四月 9, 2025， https://www.yicai.com/news/101793810.html
68. 火山引擎抢滩AI风口大模型训练云平台胜算几何？ - 证券时报, 访问时间为 四月 9, 2025， https://www.stcn.com/article/detail/845933.html
69. 火山引擎打造“多云多模型”架构，推动行业智能化升级 - 新华网, 访问时间为 四月 9, 2025， http://www.news.cn/tech/20230419/a8992baa61f243d28d4dec469261fce1/c.html
70. Claude.ai, 访问时间为 四月 9, 2025， https://claude.ai/
71. Endpoint Data Protection: Challenges & Best Practices - SentinelOne, 访问时间为 四月 9, 2025， https://www.sentinelone.com/cybersecurity-101/endpoint-security/endpoint-data-protection/
72. Top 7 Endpoint Security Risks to Watch in 2025 - Ace Cloud Hosting, 访问时间为 四月 9, 2025， https://www.acecloudhosting.com/blog/top-endpoint-security-risks/
73. The Endpoint Security Risks You Need to Know About - Impact Networking, 访问时间为 四月 9, 2025， https://www.impactmybiz.com/blog/endpoint-security-risks/
74. Oops! 5 serious gen AI security mistakes to avoid | Google Cloud Blog, 访问时间为 四月 9, 2025， https://cloud.google.com/transform/oops-5-serious-gen-ai-security-mistakes-to-avoid